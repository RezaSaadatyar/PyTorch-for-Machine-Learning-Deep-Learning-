{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Presented by: Reza Saadatyar (2024-2025)**<br/>\n",
    "**E-mail: Reza.Saadatyar@outlook.com**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1Ô∏è‚É£ CPU (Central Processing Unit) & GPU (Graphics Processing Unit):**\n",
    "- `CPU`\n",
    "  - Designed for general-purpose computing.\n",
    "  - Optimized for sequential tasks.\n",
    "  - Has a few powerful cores.\n",
    "  - Excellent at handling complex logic and single-threaded applications.\n",
    "- `GPU`\n",
    "  - Designed for parallel processing.\n",
    "  - Has thousands of smaller, less powerful cores.\n",
    "  - GPUs offer far faster numerical computing than CPUs.\n",
    "  - Optimized for tasks that can be divided into many independent calculations.\n",
    "  - Excellent for tasks like matrix operations, which are common in deep learning.\n",
    "\n",
    "Putting a tensor on GPU using `to(device)` (e.g. `some_tensor.to(device)`) returns a copy of that tensor, e.g. the same tensor will be on CPU and GPU. `some_tensor = some_tensor.to(device)`  \n",
    "\n",
    "**2Ô∏è‚É£ N-d Tensor:** A tensor is a multi-dimensional array of numerical values. Tensor computation (like numpy) with strong GPU acceleration.\n",
    "- `0-dimensional (Scalar):` A single number, e.g., 5, 3.14, -10. A <font color='red'><b>scalar</b></font> is a single number and in tensor-speak it's a zero dimension tensor.\n",
    "- `1-dimensional (Vector):` A list of numbers, e.g., [1, 2, 3]. A <font color='blue'><b>vector</b></font> is a single dimension tensor but can contain many numbers.<br/>\n",
    "- `2-dimensional (Matrix):` A table of numbers, e.g., [[1, 2], [3, 4]]. <font color='green'><b>MATRIX</b></font>  has two dimensions.\n",
    "- `3-dimensional (or higher):` Like a \"cube\" of numbers or more complex higher-dimensional structures. These are common for representing images, videos, and more.\n",
    "\n",
    "**3Ô∏è‚É£ Tensor datatypes:**<br/>\n",
    "There are many different [tensor datatypes available in PyTorch](https://pytorch.org/docs/stable/tensors.html#data-types). Some are specific for CPU and some are better for GPU.<br/>\n",
    "Generally if you see `torch.cuda` anywhere, the tensor is being used for GPU (since Nvidia GPUs use a computing toolkit called CUDA).<br/>\n",
    "The most common type (and generally the default) is `torch.float32` or `torch.float`.<br/>\n",
    "\n",
    "**4Ô∏è‚É£ Getting information from tensors:**<br/>\n",
    "* `shape` - what shape is the tensor? (some operations require specific shape rules)\n",
    "* `dtype` - what datatype are the elements within the tensor stored in?\n",
    "* `device` - what device is the tensor stored on? (usually GPU or CPU)\n",
    "\n",
    "**5Ô∏è‚É£ Math Operations:**<br/>\n",
    "* Addition ‚áí `a+b `or `torh.add(a, b)`\n",
    "* Substraction ‚áí `a-b `or `torh.sub(a, b)`\n",
    "* Multiplication (element-wise) ‚áí `a*b `\n",
    "* Division ‚áí `a/b `or `torh.div(a, b)`\n",
    "* Matrix multiplication ‚áí \"`@`\" in Python is the symbol for matrix multiplication. [`torch.matmul()`](https://pytorch.org/docs/stable/generated/torch.matmul.html) or [`torch.mm()`](https://pytorch.org/docs/stable/generated/torch.mm.html)\n",
    "  \n",
    "**6Ô∏è‚É£ Special Arrays**<br/>\n",
    "- zeros\n",
    "- ones\n",
    "- empty\n",
    "- eye\n",
    "- full<br/>\n",
    "\n",
    "Using [`torch.zeros_like(input)`](https://pytorch.org/docs/stable/generated/torch.zeros_like.html) or [`torch.ones_like(input)`](https://pytorch.org/docs/1.9.1/generated/torch.ones_like.html) which return a tensor filled with zeros or ones in the same shape as the `input` respectively.\n",
    "\n",
    "**7Ô∏è‚É£ Random Arrays**\n",
    "- `torch.rand:` Create a n*m tensor filled with random numbers from a uniform distribution on the interval [0, 1)\n",
    "- `torch.randn:` Create a n*m tensor filled with random numbers from a normal distribution with mean 0 and variance 1. \n",
    "- `torch.randint:` Create a n*m tensor filled with random integers generated uniformly between low (inclusive) and high (exclusive).\n",
    "\n",
    "`torch.randperm(value):` Create a random permutation of integers from 0 to value.<br/>\n",
    "`torch.permute(input, dims):` Permute the original tensor to rearrange the axis order.\n",
    "\n",
    "**8Ô∏è‚É£ Indexing & Slicing**\n",
    "- `Indexing`\n",
    "  - Accessing individual elements:  use integer indices to specify the position of the element you want to retrieve.\n",
    "- `Slicing`\n",
    "  - Extracting sub-tensors: Slicing allows you to extract a sub-part of your tensor by specifying a range of indices using the colon : operator.\n",
    "    - `start:end` (exclusive end)\n",
    "    - `start:` (from start to end of dimension)\n",
    "    - `:end` (from beginning to end of dimension)\n",
    "    - `:` (all elements)\n",
    "    - `start:end:step` (start to end with given step)\n",
    "  - Slicing with steps: You can include a step to skip elements in the slice. `start:end:step`\n",
    "\n",
    "**9Ô∏è‚É£ `Unsqueeze & unsqueeze:`**\n",
    "- The squeeze() method removes all singleton dimensions from a tensor. It will reduce the number of dimensions by removing the ones that have a size of 1.\n",
    "- The unsqueeze() method adds a singleton dimension at a specified position in a tensor. It will increase the number of dimensions by adding a size of 1 dimension at a specific position.\n",
    "\n",
    "**üîü `PyTorch tensors & NumPy:`**\n",
    "- [`torch.from_numpy(ndarray)`](https://pytorch.org/docs/stable/generated/torch.from_numpy.html)  NumPy array ‚Üí PyTorch tensor\n",
    "- [`torch.Tensor.numpy()`](https://pytorch.org/docs/stable/generated/torch.Tensor.numpy.html)  PyTorch tensor ‚Üí NumPy array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='#FF000e' size=\"4.5\" face=\"Arial\"><b>Import modules</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch  #  torch.__version__  -> '2.5.1+cpu'\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='#00ff0e' size=\"4.5\" face=\"Arial\"><b>CPU vs GPU</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'nvidia-smi' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "# To check if you've got access to a Nvidia GPU, you can run `!nvidia-smi` where the `!` (also called bang) means\n",
    "# \"run this on the command line\".\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.backends.mps.is_available() # Check for GPU on a Mac\n",
    "torch.cuda.is_available()           # Check for GPU on Wind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device = 'cpu', device_count = 0\n"
     ]
    }
   ],
   "source": [
    "# Set the device to 'cuda' (GPU) if a CUDA-compatible GPU is available, otherwise set it to 'cpu' (CPU)\n",
    "# This is commonly used in PyTorch to ensure computations are performed on the GPU for faster processing when available\n",
    "# device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"  # Set device type\n",
    "device_count =  torch.cuda.device_count()  # Count number of devices\n",
    "print(f\"{device = }, {device_count = }\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 2, 3]), array([1, 2, 3], dtype=int64))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Putting tensors (and models) on the GPU or CPU\n",
    "tensor = torch.tensor([1, 2, 3]) # Create tensor (default on CPU)\n",
    "tensor_on_gpu = tensor.to(device) # Move tensor to GPU (if available)\n",
    "tensor_back_on_cpu = tensor_on_gpu.cpu().numpy()  # Moving tensors back to the CPU using .cpu().numpy()\n",
    "tensor_on_gpu, tensor_back_on_cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<font color='#001240ee' size=\"4.5\" face=\"Arial\"><b>Scalar, Vector, Column vector, Matrix, & N-d Tensor</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.3333)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a 0-dimensional tensor (scalar) using PyTorch\n",
    "# A 0D tensor represents a single value, similar to a scalar in mathematics\n",
    "torch.tensor(4/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a = tensor([1, 2, 3]) --> a.__class__ = <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# Create a 1-dimensional tensor (vector) using PyTorch\n",
    "# A 1D tensor is a list of values, similar to a vector in mathematics\n",
    "a = torch.tensor([1, 2, 3])\n",
    "\n",
    "# The `__class__` attribute shows the type of the object, which is `torch.Tensor`\n",
    "print(f\"{a = } --> {a.__class__ = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4]])\n"
     ]
    }
   ],
   "source": [
    "# Create a 2-dimensional tensor (column vector) using PyTorch\n",
    "# A 2D tensor is a matrix with rows and columns\n",
    "column_vector = torch.tensor([[1], [2], [3], [4]]) # This results in a column vector with 4 rows and 1 column\n",
    "print(column_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n"
     ]
    }
   ],
   "source": [
    "# Create a 2-dimensional tensor (matrix) using PyTorch\n",
    "# A 2D tensor is a matrix with rows and columns\n",
    "matrix = torch.tensor(\n",
    "    [[1, 2, 3],\n",
    "     [4, 5, 6],\n",
    "     [7, 8, 9]]\n",
    ")\n",
    "print(matrix) # The resulting tensor is a 2D tensor with shape (3, 3), representing a 3x3 matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 2, 2, 5],\n",
      "         [3, 4, 0, 8]],\n",
      "\n",
      "        [[5, 6, 6, 7],\n",
      "         [4, 8, 1, 2]],\n",
      "\n",
      "        [[1, 1, 8, 9],\n",
      "         [0, 0, 2, 3]]])\n"
     ]
    }
   ],
   "source": [
    "# Create a 3-dimensional tensor using PyTorch\n",
    "# A 3D tensor can be thought of as a collection of matrices (2D tensors) stacked along a third dimension\n",
    "# Here, the tensor is created from a nested list structure with three levels:\n",
    "# - The outer list represents the \"depth\" or \"channels\" (3 in this case).\n",
    "# - The middle lists represent the rows of each matrix (2 in this case).\n",
    "# - The inner lists represent the columns of each matrix (4 in this case).\n",
    "tensor_3d = torch.tensor(\n",
    "    [[[1, 2, 2, 5],\n",
    "      [3, 4, 0, 8]],\n",
    "\n",
    "     [[5, 6, 6, 7],\n",
    "      [4, 8, 1, 2]],\n",
    "\n",
    "     [[1, 1, 8, 9],\n",
    "      [0, 0, 2, 3]]]\n",
    ")\n",
    "\n",
    "# The resulting tensor is a 3D tensor with shape (3, 2, 4), representing:\n",
    "# - 3 matrices (depth/channels)\n",
    "# - Each matrix has 2 rows and 4 columns\n",
    "print(tensor_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1, 2, 5, 4],\n",
      "          [3, 4, 1, 0]],\n",
      "\n",
      "         [[5, 6, 2, 3],\n",
      "          [7, 8, 6, 4]]]])\n"
     ]
    }
   ],
   "source": [
    "# Create a 4-dimensional tensor using PyTorch\n",
    "# A 4D tensor can be thought of as a collection of 3D tensors stacked along a fourth dimension\n",
    "# Here, the tensor is created from a nested list structure with four levels:\n",
    "# - The outer list represents the \"batch\" dimension (1 in this case).\n",
    "# - The next level represents the \"depth\" or \"channels\" (2 in this case).\n",
    "# - The next level represents the rows of each matrix (2 in this case).\n",
    "# - The innermost lists represent the columns of each matrix (4 in this case).\n",
    "tensor_4d = torch.tensor(\n",
    "    [[[[1, 2, 5, 4],\n",
    "       [3, 4, 1, 0]],\n",
    "      [[5, 6, 2, 3],\n",
    "       [7, 8, 6, 4]]]]\n",
    ")\n",
    "\n",
    "# The resulting tensor is a 4D tensor with shape (1, 2, 2, 4), representing:\n",
    "# - 1 batch\n",
    "# - 2 channels/depth\n",
    "# - Each channel has 2 rows and 4 columns\n",
    "print(tensor_4d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='#ff555e2' size=\"4.5\" face=\"Arial\"><b>Getting information from tensors</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.float32, device(type='cpu'))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Default datatype for tensors is float32\n",
    "float_32_tensor = torch.tensor([1.0, 5.0, 6.0],\n",
    "                               dtype=None, # defaults to None, which is torch.float32 or whatever datatype is passed\n",
    "                               device=None, # defaults to None, which uses the default tensor type\n",
    "                               requires_grad=False) # if True, operations performed on the tensor are recorded \n",
    "\n",
    "float_32_tensor.dtype, float_32_tensor.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a = tensor(1.3333, dtype=torch.float64) --> a.shape = torch.Size([]), a.ndim = 0, a.size() = torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "# Create a 0-dimensional tensor (scalar) using PyTorch\n",
    "# A 0D tensor represents a single value, similar to a scalar in mathematics\n",
    "# The tensor is explicitly set to have a data type of `torch.float64` (64-bit floating point) and is placed on the CPU\n",
    "a = torch.tensor(4/3, dtype=torch.float64, device=\"cpu\")\n",
    "\n",
    "# Print the tensor and its properties:\n",
    "# - `a.shape`: The shape of the tensor (empty tuple for 0D tensors)\n",
    "# - `a.ndim`: The number of dimensions (0 for a scalar)\n",
    "# - `a.size()`: The size of the tensor (same as shape for 0D tensors)\n",
    "print(f\"{a = } --> {a.shape = }, {a.ndim = }, {a.size() = }\")\n",
    "\n",
    "# Convert the tensor to a different data type, `torch.float16` (16-bit floating point)\n",
    "# This reduces the precision of the tensor but can save memory and improve performance\n",
    "a_float16 = a.type(torch.float16)\n",
    "# Alternatively, you can use `a.short()` to convert to a 16-bit integer, but this is not applicable here since the tensor is floating-point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6]])\n"
     ]
    }
   ],
   "source": [
    "# Create a tuple of tuples, where each inner tuple contains two integers\n",
    "a = tuple([(1, 2), (3, 4), (5, 6)])\n",
    "tensor_a = torch.tensor(a) # Convert the tuple of tuples into a PyTorch tensor\n",
    "print(tensor_a) # The resulting tensor is a 2D tensor with shape (3, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"#ff0051e2\" size=\"4.5\" face=\"Arial\"><b>Math Operations</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 2.0, Standard Deviation: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Create a 1-dimensional tensor (vector) with integer values\n",
    "a = torch.tensor([1, 2, 3])\n",
    "\n",
    "# Convert the tensor to `float` type using `.float()` to ensure the mean is computed as a floating-point value\n",
    "mean_value = a.float().mean() # Calculate the mean of the tensor\n",
    "\n",
    "# Convert the tensor to `torch.float32` type using `.type(torch.float32)` to ensure the standard deviation is computed as a floating-point value\n",
    "std_value = a.type(torch.float32).std() # Calculate the standard deviation of the tensor\n",
    "print(f\"Mean: {mean_value}, Standard Deviation: {std_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[3, 6],\n",
       "         [5, 0]]),\n",
       " tensor([[3, 2],\n",
       "         [7, 9]]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create two 2D tensors (matrices) with random integer values between 0 and 10\n",
    "a = torch.randint(10, (2, 2))  # 2x2 tensor\n",
    "b = torch.randint(10, (2, 2))  # 2x2 tensor\n",
    "a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 6,  8],\n",
       "         [12,  9]]),\n",
       " tensor([[ 0,  4],\n",
       "         [-2, -9]]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adds corresponding elements of `a` and `b`\n",
    "# Subtracts elements of `b` from corresponding elements of `a`\n",
    "torch.add(a, b, ), torch.sub(a, b, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Element-wise multiplication:\n",
      "tensor([[ 9, 12],\n",
      "        [35,  0]])\n",
      "Matrix multiplication (using @):\n",
      "tensor([[51, 60],\n",
      "        [15, 10]])\n",
      "Matrix multiplication (using torch.matmul):\n",
      "tensor([[51, 60],\n",
      "        [15, 10]])\n"
     ]
    }
   ],
   "source": [
    "# Element-wise multiplication using `*` (Multiplies corresponding elements of `a` and `b`)\n",
    "elementwise_mul = a * b\n",
    "\n",
    "# Matrix multiplication using `@` (Performs matrix multiplication of `a` and `b`)\n",
    "matrix_mul = a @ b\n",
    "\n",
    "# Matrix multiplication using `torch.matmul()` (Performs matrix multiplication of `a` and `b`)\n",
    "matmul_result = torch.matmul(a, b)\n",
    "\n",
    "print(f\"Element-wise multiplication:\\n{elementwise_mul}\")\n",
    "print(f\"Matrix multiplication (using @):\\n{matrix_mul}\")\n",
    "print(f\"Matrix multiplication (using torch.matmul):\\n{matmul_result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Element-wise division:\n",
      "tensor([[0.4000, 1.2500],\n",
      "        [4.0000, 4.0000]])\n"
     ]
    }
   ],
   "source": [
    "# Perform element-wise division of two 2D tensors `a` and `b`\n",
    "a = torch.randint(10, (2, 2))  # 2x2 tensor with random integer values between 0 and 10\n",
    "b = torch.randint(1, 10, (2, 2))  # 2x2 tensor with random integer values between 1 and 10 (to avoid division by zero)\n",
    "\n",
    "# Element-wise division using `/` (Divides corresponding elements of `a` by `b`)\n",
    "elementwise_div = a / b\n",
    "print(f\"Element-wise division:\\n{elementwise_div}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"#00ff21aa\" size=\"4.5\" face=\"Arial\"><b>Special Arrays</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [1.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a 2D tensor filled with ones using PyTorch\n",
    "torch.ones((2, 1))  # The tensor has a shape of (2, 1), meaning it has 2 rows and 1 column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a 3D tensor filled with zeros using PyTorch\n",
    "# The tensor has a shape of (3, 4, 3), meaning:\n",
    "# - 3 matrices (depth/channels)\n",
    "# - Each matrix has 4 rows and 3 columns\n",
    "torch.zeros((3, 4, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The tensor has a shape of (5, 4), meaning it has 5 rows and 4 columns\n",
    "torch.eye(5, 4) # The diagonal elements are set to 1, and all other elements are set to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 2, 2],\n",
       "        [2, 2, 2],\n",
       "        [2, 2, 2],\n",
       "        [2, 2, 2]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The tensor has a shape of (4, 3), meaning it has 4 rows and 3 columns\n",
    "torch.full([4, 3], fill_value=2) # All elements in the tensor are set to the `fill_value` (2 in this case)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"#22aa1232\" size=\"4.5\" face=\"Arial\"><b>Random Arrays</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4657, 0.2328, 0.4527],\n",
       "        [0.5871, 0.4086, 0.1272],\n",
       "        [0.6373, 0.2421, 0.7312],\n",
       "        [0.7224, 0.1992, 0.6948]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(12) # Set a manual seed for reproducibility\n",
    "torch.rand((4, 3)) # Create a 2D tensor with random values uniformly distributed between 0 and 1 (shape of (4, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[12,  3,  9],\n",
       "        [11,  2, 10],\n",
       "        [ 8,  3,  3],\n",
       "        [10, 11,  2]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set a manual seed for reproducibility\n",
    "torch.manual_seed(12)\n",
    "\n",
    "# Create a 2D tensor with random integer values within a specified range\n",
    "# The range is from 2 (inclusive) to 13 (exclusive)\n",
    "torch.randint(2, 13, (4, 3)) # The tensor has a shape of (4, 3), meaning it has 4 rows and 3 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"#22aa1232\" size=\"4.5\" face=\"Arial\"><b>Randperm & permute</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 8, 7, 6, 4, 5, 2, 9, 1, 0])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a random permutation of integers from 0 to 9\n",
    "torch.randperm(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous shape: torch.Size([224, 224, 3])\n",
      "New shape: torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor with a specific shape (224, 224, 3) using random values\n",
    "# This shape is commonly used for RGB images, where:\n",
    "# - 224 is the height\n",
    "# - 224 is the width\n",
    "# - 3 is the number of color channels (Red, Green, Blue)\n",
    "original = torch.rand(size=(224, 224, 3))\n",
    "\n",
    "# Permute the tensor to rearrange the order of its axes\n",
    "# The `permute()` method reorders the dimensions of the tensor\n",
    "# Here, the new order is (2, 0, 1), which means:\n",
    "# - The original axis 2 (channels) becomes the new axis 0\n",
    "# - The original axis 0 (height) becomes the new axis 1\n",
    "# - The original axis 1 (width) becomes the new axis 2\n",
    "permuted = original.permute(2, 0, 1)\n",
    "\n",
    "# Print the shapes of the original and permuted tensors\n",
    "print(f\"Previous shape: {original.shape}\")\n",
    "print(f\"New shape: {permuted.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"#bb1254ff\" size=\"4.5\" face=\"Arial\"><b>Indexing & Slicing</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: tensor([ 1.1538,  0.3991,  0.2250,  0.2924,  0.0614, -0.2668, -1.3685, -1.1728,\n",
      "         0.1342, -0.2616, -1.5436,  0.2017])\n",
      "a[0:1]: tensor([1.1538])\n",
      "a[0]: 1.1538151502609253\n",
      "a[[0, 2, 7]]: tensor([ 1.1538,  0.2250, -1.1728])\n"
     ]
    }
   ],
   "source": [
    "# Create a 1D tensor with 12 random values from a standard normal distribution (mean=0, std=1)\n",
    "a = torch.randn(12)\n",
    "print(f\"a: {a}\")\n",
    "print(f\"a[0:1]: {a[0:1]}\") # A slice of the tensor containing the first element (as a 1D tensor)\n",
    "print(f\"a[0]: {a[0]}\")     # The first element of the tensor (as a scalar)\n",
    "print(f\"a[[0, 2, 7]]: {a[[0, 2, 7]]}\") # A tensor containing the elements at indices 0, 2, and 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.2250,  0.0614, -1.3685,  0.1342, -1.5436]),\n",
       " tensor([ 0.2250,  0.0614, -1.3685,  0.1342, -1.5436]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `a[2:12:2]`: Slice the tensor from index 2 to index 12 (exclusive) with a step of 2\n",
    "# `a[2::2]`: Slice the tensor from index 2 to the end with a step of 2\n",
    "a[2:12:2], a[2::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.6282,  1.0835],\n",
       "         [-1.4616, -0.2670],\n",
       "         [-0.8549,  0.1933]]),\n",
       " tensor([[ 0.6282,  1.0835],\n",
       "         [-1.4616, -0.2670],\n",
       "         [-0.8549,  0.1933]]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(3,5)\n",
    "a[0:3, 2:-1], a[:, 2:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.0210,  0.9056],\n",
       "         [ 1.0438,  0.3598],\n",
       "         [-0.3547, -0.2390]]),\n",
       " tensor([[ 1.0210,  0.9056],\n",
       "         [ 1.0438,  0.3598],\n",
       "         [-0.3547, -0.2390]]))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.3641,  0.4331,  0.5895, -1.2568,  0.4411],\n",
       "         [-0.2782, -0.2588, -0.4724,  1.0558,  0.5683]]),\n",
       " tensor([[ 0.3641,  0.4331,  0.5895, -1.2568,  0.4411],\n",
       "         [-0.2782, -0.2588, -0.4724,  1.0558,  0.5683]]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0:2], a[0:2, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5895, -1.2568,  0.4411],\n",
       "        [ 1.9573, -0.3660, -0.2266]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[::2, 2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 4.2969e-01,  1.1980e+00, -1.0833e+00,  3.5402e-01,  7.9477e-01,\n",
       "           2.3819e+00, -3.7064e-01],\n",
       "         [-7.9222e-01, -8.3236e-01, -3.2613e-01,  1.7579e+00,  3.6650e-01,\n",
       "          -3.3034e-02, -1.3126e+00],\n",
       "         [-9.2532e-01, -3.8545e-01, -5.3512e-01,  4.0278e-01,  1.1849e-01,\n",
       "           2.9048e+00,  1.4602e+00],\n",
       "         [ 1.5539e+00, -1.5911e+00, -2.1023e-01, -9.3761e-01,  5.8109e-01,\n",
       "          -2.9350e-01, -8.0874e-01],\n",
       "         [-3.1397e-01, -1.9417e+00, -1.8543e+00,  2.7558e-01, -5.9811e-01,\n",
       "          -3.8076e-01,  3.5677e-03],\n",
       "         [ 2.4633e-01,  1.3368e-01, -1.0755e+00,  1.9913e+00, -1.4785e+00,\n",
       "          -1.3697e+00, -5.6596e-01]],\n",
       "\n",
       "        [[ 1.1672e+00, -1.7709e+00, -4.4624e-01,  7.9434e-01,  7.4588e-01,\n",
       "           3.8383e-01,  4.3685e-01],\n",
       "         [ 8.1806e-01, -1.0156e+00, -5.4061e-01,  1.5879e-01, -4.2923e-01,\n",
       "           4.3937e-01, -1.3256e-01],\n",
       "         [ 1.7277e+00,  9.3084e-01,  1.4519e+00, -4.9755e-01,  6.5133e-01,\n",
       "          -2.1107e-01,  2.7395e-01],\n",
       "         [-1.1969e+00, -6.0858e-01,  8.9590e-01,  2.1258e+00, -2.7747e-02,\n",
       "           3.8384e-01, -1.7151e+00],\n",
       "         [ 4.1471e-01,  8.3979e-01,  3.4220e-01, -2.3196e+00,  7.6225e-01,\n",
       "           6.2045e-01,  2.3008e-01],\n",
       "         [-1.7236e+00,  7.5226e-01, -5.6694e-01,  7.9610e-01, -3.5459e-01,\n",
       "          -1.5467e+00,  5.2085e-01]],\n",
       "\n",
       "        [[ 4.6108e-01, -9.1255e-01, -6.7037e-01, -1.5016e+00, -2.4462e+00,\n",
       "           2.2535e-01,  6.0805e-01],\n",
       "         [-6.7050e-02, -2.5667e-01,  6.6530e-01,  3.4849e-01, -3.0517e-01,\n",
       "           1.1489e+00,  1.2861e+00],\n",
       "         [ 4.6786e-01,  4.2048e-01,  8.6716e-01,  1.0610e-01,  1.1346e+00,\n",
       "           7.6687e-01,  9.1297e-01],\n",
       "         [ 2.1123e-01,  1.2541e-01, -7.8015e-01, -6.8554e-02, -8.3586e-01,\n",
       "          -4.6496e-01, -4.7118e-01],\n",
       "         [-3.6919e-01,  1.8396e-01,  9.3915e-01, -6.2772e-01, -3.8302e-02,\n",
       "          -1.0608e+00,  9.2034e-02],\n",
       "         [ 1.1882e+00,  2.4564e-03, -1.2157e+00, -2.9878e-01,  8.1731e-03,\n",
       "          -4.7928e-01,  1.1607e+00]],\n",
       "\n",
       "        [[ 1.7413e+00, -1.6035e+00, -1.5472e+00,  1.4353e-02, -5.9002e-01,\n",
       "           4.7920e-01,  1.1845e+00],\n",
       "         [-1.5000e+00,  7.0517e-01,  1.8130e-01,  4.5851e-01, -8.7532e-01,\n",
       "          -1.0450e+00, -2.0075e-01],\n",
       "         [-4.9694e-01, -6.8697e-01,  1.2904e+00, -6.2279e-01,  1.2720e-01,\n",
       "          -5.2066e-01, -2.1612e-01],\n",
       "         [ 3.5481e-01,  4.4950e-01, -5.7936e-01,  4.6835e-01,  8.1213e-01,\n",
       "           4.0012e-01,  1.1803e-01],\n",
       "         [ 3.2844e-01,  1.8744e-01, -1.4583e-01, -9.2184e-01,  7.1015e-01,\n",
       "          -1.0031e+00,  1.2937e+00],\n",
       "         [-1.8393e-01, -5.1315e-01,  1.0776e+00, -1.0983e+00, -6.4279e-01,\n",
       "          -7.2658e-01,  7.5722e-01]]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(4, 6, 7)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.8959,  2.1258],\n",
       "          [ 0.3422, -2.3196]]]),\n",
       " tensor([[[ 0.8959,  2.1258],\n",
       "          [ 0.3422, -2.3196]]]),\n",
       " tensor([[ 0.8959,  2.1258],\n",
       "         [ 0.3422, -2.3196]]))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[1:2, 3:5, 2:4], a[[1], 3:5, 2:4], a[1, 3:5, 2:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.1672, -1.7709, -0.4462,  0.7943,  0.7459,  0.3838,  0.4369],\n",
       "         [ 0.8181, -1.0156, -0.5406,  0.1588, -0.4292,  0.4394, -0.1326],\n",
       "         [ 1.7277,  0.9308,  1.4519, -0.4976,  0.6513, -0.2111,  0.2740],\n",
       "         [-1.1969, -0.6086,  0.8959,  2.1258, -0.0277,  0.3838, -1.7151],\n",
       "         [ 0.4147,  0.8398,  0.3422, -2.3196,  0.7623,  0.6204,  0.2301],\n",
       "         [-1.7236,  0.7523, -0.5669,  0.7961, -0.3546, -1.5467,  0.5208]]),\n",
       " tensor([[-0.3706, -1.3126,  1.4602, -0.8087,  0.0036, -0.5660],\n",
       "         [ 0.4369, -0.1326,  0.2740, -1.7151,  0.2301,  0.5208],\n",
       "         [ 0.6081,  1.2861,  0.9130, -0.4712,  0.0920,  1.1607],\n",
       "         [ 1.1845, -0.2007, -0.2161,  0.1180,  1.2937,  0.7572]]),\n",
       " tensor([[-0.3706, -1.3126,  1.4602, -0.8087,  0.0036, -0.5660],\n",
       "         [ 0.4369, -0.1326,  0.2740, -1.7151,  0.2301,  0.5208],\n",
       "         [ 0.6081,  1.2861,  0.9130, -0.4712,  0.0920,  1.1607],\n",
       "         [ 1.1845, -0.2007, -0.2161,  0.1180,  1.2937,  0.7572]]))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[1], a[:, :, -1], a[..., -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"#aaff5499\" size=\"4.5\" face=\"Arial\"><b>Unsqueeze & squeeze</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape of tensor_a: torch.Size([1, 3, 1, 4, 1])\n",
      "Squeezed shape of tensor_b: torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "# Removing all singleton dimensions\n",
    "tensor_a = torch.randn(1, 3, 1, 4, 1)\n",
    "print(\"Original shape of tensor_a:\", tensor_a.shape)  # Output: torch.Size([1, 3, 1, 4, 1])\n",
    "\n",
    "tensor_b = tensor_a.squeeze()\n",
    "print(\"Squeezed shape of tensor_b:\", tensor_b.shape)  # Output: torch.Size([3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape of a: torch.Size([2, 1, 3, 1, 4])\n",
      "a.squeeze(0).shape = torch.Size([2, 1, 3, 1, 4])\n",
      "a.squeeze(1).shape = torch.Size([2, 3, 1, 4])\n",
      "a.squeeze(3).shape = torch.Size([2, 1, 3, 4])\n",
      "a.squeeze().shape = torch.Size([2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "# Removing a specific singleton dimension\n",
    "a = torch.randn(2, 1, 3, 1, 4)\n",
    "print(\"Original shape of a:\", a.shape)  # Output: torch.Size([2, 1, 3, 1, 4])\n",
    "\n",
    "# Remove the first dimension (index 0) which is not 1, so no change is done; Output: torch.Size([2, 1, 3, 1, 4])\n",
    "print(f\"{a.squeeze(0).shape = }\")\n",
    "\n",
    "# Remove the second dimension (index 1) which is size 1; Output: torch.Size([2, 3, 1, 4])\n",
    "print(f\"{a.squeeze(1).shape = }\")\n",
    "\n",
    "# Remove the fourth dimension (index 3) which is size 1; Output: torch.Size([2, 1, 3, 4])\n",
    "print(f\"{a.squeeze(3).shape = }\")\n",
    "\n",
    "print(f\"{a.squeeze().shape = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: tensor([[ 0.8279,  1.1309],\n",
      "        [-0.8629,  2.1094]])\n",
      "b.unsqueeze(0) = tensor([[[ 0.8279,  1.1309],\n",
      "         [-0.8629,  2.1094]]]) --> b.unsqueeze(0).shape = torch.Size([1, 2, 2])\n",
      "b.unsqueeze(1) = tensor([[[ 0.8279,  1.1309]],\n",
      "\n",
      "        [[-0.8629,  2.1094]]]) --> b.unsqueeze(1).shape = torch.Size([2, 1, 2])\n",
      "b.unsqueeze(2) = tensor([[[ 0.8279],\n",
      "         [ 1.1309]],\n",
      "\n",
      "        [[-0.8629],\n",
      "         [ 2.1094]]]) --> b.unsqueeze(2).shape = torch.Size([2, 2, 1])\n"
     ]
    }
   ],
   "source": [
    "b = torch.randn(2, 2)\n",
    "print(\"Original:\", b)  # Output: torch.Size([3, 4])\n",
    "\n",
    "# Add dimension at the beginning (index 0); # Output: torch.Size([1, 3, 4])\n",
    "print(f\"{b.unsqueeze(0) = } --> {b.unsqueeze(0).shape = }\")\n",
    "# Add dimension in between the two dimensions (index 1); Output: torch.Size([3, 1, 4])\n",
    "print(f\"{b.unsqueeze(1) = } --> {b.unsqueeze(1).shape = }\")\n",
    "\n",
    "# Add dimension at the end (index 2); Output: torch.Size([3, 4, 1])\n",
    "print(f\"{b.unsqueeze(2) = } --> {b.unsqueeze(2).shape = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='#hh99gg99' size='4.5' face=\"Arial\"><b>PyTorch tensors & NumPy</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 2., 3., 4., 5., 6., 7.]),\n",
       " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64),\n",
       " array([1., 2., 3., 4., 5., 6., 7.]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array = np.arange(1.0, 8.0)\n",
    "tensor = torch.from_numpy(array)\n",
    "nump = torch.Tensor.numpy(tensor)\n",
    "array, tensor, nump"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
